{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inory in Spanish Tweets (Random Forest Model)\n",
    "\n",
    "### Building a predictive model using "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "popular_words = stopwords.words('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with io.open('data/corpus.txt','r',encoding='utf8') as f:\n",
    "    corpus = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "supreme = []\n",
    "for tweet in corpus:\n",
    "        supreme.append(tweet.split('|',2)[-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_array = np.array(supreme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=corpus_array,columns=['cat','tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ironic</td>\n",
       "      <td>No hay casi nadie de Cuenca en Benidorm üòÜüòÜüòÜ \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ironic</td>\n",
       "      <td>QuienLoHubieraDicho hacer tuneles es mas facil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>not_ironic</td>\n",
       "      <td>\"La vida era madre f√°cil cuando no hab√≠a Twitt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>not_ironic</td>\n",
       "      <td>\"Oh no se para qu√© hablo con esta guachenga.. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>not_ironic</td>\n",
       "      <td>\"¬øQu√© fue lo primero que se te vino a la cabez...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          cat                                              tweet\n",
       "0      ironic     No hay casi nadie de Cuenca en Benidorm üòÜüòÜüòÜ \\n\n",
       "1      ironic  QuienLoHubieraDicho hacer tuneles es mas facil...\n",
       "2  not_ironic  \"La vida era madre f√°cil cuando no hab√≠a Twitt...\n",
       "3  not_ironic  \"Oh no se para qu√© hablo con esta guachenga.. ...\n",
       "4  not_ironic  \"¬øQu√© fue lo primero que se te vino a la cabez..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cat      15306\n",
       "tweet    15306\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline_svm = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer='word',stop_words=popular_words,min_df=10,ngram_range=(1,6))),\n",
    "    ('tfidf', TfidfTransformer()), \n",
    "    ('classifier', SVC(kernel='linear')),  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline_rand_forest = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer='char',stop_words=popular_words,min_df=10,ngram_range=(1,6))),\n",
    "    ('tfidf', TfidfTransformer()), \n",
    "    ('classifier', RandomForestClassifier(n_estimators=200)),  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10255, 5051, 15306)\n"
     ]
    }
   ],
   "source": [
    "tweet_train, tweet_test, label_train, label_test = \\\n",
    "train_test_split(df['tweet'], df['cat'], test_size=0.33)\n",
    "\n",
    "print(len(tweet_train), len(tweet_test), len(tweet_train) + len(tweet_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('bow', CountVectorizer(analyzer='word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=10,\n",
       "        ngram_range=(1, 6), preprocessor=None,\n",
       "        stop_words=[u'de', u...,\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_svm.fit(tweet_train,label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('bow', CountVectorizer(analyzer='char', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=10,\n",
       "        ngram_range=(1, 6), preprocessor=None,\n",
       "        stop_words=[u'de', u...mators=200, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_rand_forest.fit(tweet_train,label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9856     Odio descansar los lunes  beach espi√±eiro play...\n",
      "5564     \"@ Que sea este lunes un buen inicio de semana...\n",
      "3170     @ pero all√≠ pues Ud troll a favor de Rodas (co...\n",
      "9544     ¬°Qu√© originalidad de chica! ¬°Qu√© perdonalidad ...\n",
      "13963    \"Como quisiera ayudarte a olvidar tu pasado. üòã\"\\n\n",
      "Name: tweet, dtype: object\n",
      "614          \"Son unas genias estas minas como cantan üòÜ\"\\n\n",
      "14239    Que dura es la vida...... vacaciones  monster ...\n",
      "5874                               Oleeee mi orgullo üëèüëè \\n\n",
      "13447    \"@ gracias Don Gustavo,no hay que dejar que cu...\n",
      "4020     \"@  jaja es hermoso √©l... Ni se compara... Com...\n",
      "Name: tweet, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print tweet_test.head()\n",
    "print tweet_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_svm = pipeline_svm.predict(tweet_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_tree = pipeline_rand_forest.predict(tweet_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     ironic       0.74      0.67      0.70      2514\n",
      " not_ironic       0.70      0.77      0.73      2537\n",
      "\n",
      "avg / total       0.72      0.72      0.72      5051\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"Support Vector Machine\"\n",
    "print (classification_report(label_test,predictions_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     ironic       1.00      0.98      0.99      2514\n",
      " not_ironic       0.98      1.00      0.99      2537\n",
      "\n",
      "avg / total       0.99      0.99      0.99      5051\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"Random Forest\"\n",
    "print (classification_report(label_test,predictions_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
