{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Pre proccessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building 10-90 distribution data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'data/corpus_10_90.txt.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-386c9f14a945>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/corpus_10_90.txt.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mcorpus_10_90\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'data/corpus_10_90.txt.txt'"
     ]
    }
   ],
   "source": [
    "with io.open('data/corpus_10_90.txt.txt','r',encoding='utf8') as f:\n",
    "    corpus_10_90 = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "supreme = []\n",
    "for tweet in corpus:\n",
    "        supreme.append(tweet.split('|',2)[-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def  change_value(strings):\n",
    "    if strings == 'ironic':\n",
    "        return int(1)\n",
    "    else:\n",
    "        return int(0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_array = np.array(supreme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_corpus = pd.DataFrame(data=corpus_array,columns=['cat','tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lel = df_corpus['cat'].apply(change_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_corpus.insert(loc=2,column='category',value=lel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets = df_corpus['tweet'].iloc[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>tweet</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ironic</td>\n",
       "      <td>No hay casi nadie de Cuenca en Benidorm ðŸ˜†ðŸ˜†ðŸ˜† \\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ironic</td>\n",
       "      <td>QuienLoHubieraDicho hacer tuneles es mas facil...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>not_ironic</td>\n",
       "      <td>\"La vida era madre fÃ¡cil cuando no habÃ­a Twitt...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>not_ironic</td>\n",
       "      <td>\"Oh no se para quÃ© hablo con esta guachenga.. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>not_ironic</td>\n",
       "      <td>\"Â¿QuÃ© fue lo primero que se te vino a la cabez...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          cat                                              tweet  category\n",
       "0      ironic     No hay casi nadie de Cuenca en Benidorm ðŸ˜†ðŸ˜†ðŸ˜† \\n         1\n",
       "1      ironic  QuienLoHubieraDicho hacer tuneles es mas facil...         1\n",
       "2  not_ironic  \"La vida era madre fÃ¡cil cuando no habÃ­a Twitt...         0\n",
       "3  not_ironic  \"Oh no se para quÃ© hablo con esta guachenga.. ...         0\n",
       "4  not_ironic  \"Â¿QuÃ© fue lo primero que se te vino a la cabez...         0"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=20000,lower=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(tweets)\n",
    "tokenizer.word_index\n",
    "lista = tokenizer.texts_to_sequences(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_corpus.insert(loc=3,column='tweet_sec', value=lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(lista[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>tweet</th>\n",
       "      <th>category</th>\n",
       "      <th>tweet_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ironic</td>\n",
       "      <td>No hay casi nadie de Cuenca en Benidorm ðŸ˜†ðŸ˜†ðŸ˜† \\n</td>\n",
       "      <td>1</td>\n",
       "      <td>[33, 54, 259, 177, 2, 4493, 8, 9784, 9785]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ironic</td>\n",
       "      <td>QuienLoHubieraDicho hacer tuneles es mas facil...</td>\n",
       "      <td>1</td>\n",
       "      <td>[9786, 82, 9787, 12, 45, 1666, 1, 82, 1667, 60...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>not_ironic</td>\n",
       "      <td>\"La vida era madre fÃ¡cil cuando no habÃ­a Twitt...</td>\n",
       "      <td>0</td>\n",
       "      <td>[59, 61, 151, 212, 719, 24, 6, 379, 561]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>not_ironic</td>\n",
       "      <td>\"Oh no se para quÃ© hablo con esta guachenga.. ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[459, 6, 14, 25, 72, 526, 22, 19, 9790, 39, 52...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>not_ironic</td>\n",
       "      <td>\"Â¿QuÃ© fue lo primero que se te vino a la cabez...</td>\n",
       "      <td>0</td>\n",
       "      <td>[296, 100, 17, 271, 1, 14, 21, 354, 3, 4, 192,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          cat                                              tweet  category  \\\n",
       "0      ironic     No hay casi nadie de Cuenca en Benidorm ðŸ˜†ðŸ˜†ðŸ˜† \\n         1   \n",
       "1      ironic  QuienLoHubieraDicho hacer tuneles es mas facil...         1   \n",
       "2  not_ironic  \"La vida era madre fÃ¡cil cuando no habÃ­a Twitt...         0   \n",
       "3  not_ironic  \"Oh no se para quÃ© hablo con esta guachenga.. ...         0   \n",
       "4  not_ironic  \"Â¿QuÃ© fue lo primero que se te vino a la cabez...         0   \n",
       "\n",
       "                                           tweet_sec  \n",
       "0         [33, 54, 259, 177, 2, 4493, 8, 9784, 9785]  \n",
       "1  [9786, 82, 9787, 12, 45, 1666, 1, 82, 1667, 60...  \n",
       "2           [59, 61, 151, 212, 719, 24, 6, 379, 561]  \n",
       "3  [459, 6, 14, 25, 72, 526, 22, 19, 9790, 39, 52...  \n",
       "4  [296, 100, 17, 271, 1, 14, 21, 354, 3, 4, 192,...  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vector_corpus = df_corpus[['category','tweet_sec']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vector_corpus.to_csv(path_or_buf='./data/corpus_vectorized.txt', sep='|',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>tweet_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[33, 54, 259, 177, 2, 4493, 8, 9784, 9785]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[9786, 82, 9787, 12, 45, 1666, 1, 82, 1667, 60...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[59, 61, 151, 212, 719, 24, 6, 379, 561]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[459, 6, 14, 25, 72, 526, 22, 19, 9790, 39, 52...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[296, 100, 17, 271, 1, 14, 21, 354, 3, 4, 192,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category                                          tweet_sec\n",
       "0         1         [33, 54, 259, 177, 2, 4493, 8, 9784, 9785]\n",
       "1         1  [9786, 82, 9787, 12, 45, 1666, 1, 82, 1667, 60...\n",
       "2         0           [59, 61, 151, 212, 719, 24, 6, 379, 561]\n",
       "3         0  [459, 6, 14, 25, 72, 526, 22, 19, 9790, 39, 52...\n",
       "4         0  [296, 100, 17, 271, 1, 14, 21, 354, 3, 4, 192,..."
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_features = 20000\n",
    "maxlen = 20\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweet_train, tweet_test, label_train, label_test = \\\n",
    "train_test_split(vector_corpus['tweet_sec'], vector_corpus['category'], test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4811                              [441, 364, 193, 13, 94]\n",
      "8395    [62, 12, 4, 3964, 16, 215, 1, 54, 1038, 14, 21...\n",
      "7883    [2521, 4332, 16, 734, 5, 8, 619, 3115, 6728, 1...\n",
      "889       [451, 14, 9, 2737, 7, 3190, 32, 4755, 133, 771]\n",
      "4520    [147, 9, 653, 15715, 29, 6, 9, 116, 79, 15716,...\n",
      "Name: tweet_sec, dtype: object\n",
      "5051\n"
     ]
    }
   ],
   "source": [
    "print tweet_test.head()\n",
    "print tweet_test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7676     [281, 815, 19, 96, 529, 1069, 5, 12, 862, 98, ...\n",
      "13215    [6182, 126, 49, 4, 4718, 27, 665, 2, 94, 8, 11...\n",
      "14494    [107, 77, 101, 9728, 48, 1245, 1270, 2982, 1, ...\n",
      "5999          [7069, 1605, 17478, 17479, 24, 155, 12, 106]\n",
      "15074    [60, 1865, 1130, 816, 182, 1447, 2282, 98, 67,...\n",
      "Name: tweet_sec, dtype: object\n",
      "10255\n"
     ]
    }
   ],
   "source": [
    "print tweet_train.head()\n",
    "print tweet_train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "('x_train shape:', (10255, 20))\n",
      "('x_test shape:', (5051, 20))\n"
     ]
    }
   ],
   "source": [
    "print('Pad sequences (samples x time)')\n",
    "tweet_train = sequence.pad_sequences(tweet_train, maxlen=maxlen)\n",
    "tweet_test = sequence.pad_sequences(tweet_test, maxlen=maxlen)\n",
    "print('x_train shape:', tweet_train.shape)\n",
    "print('x_test shape:', tweet_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 10255 samples, validate on 5051 samples\n",
      "Epoch 1/20\n",
      "10255/10255 [==============================] - 25s - loss: 0.2961 - acc: 0.8859 - val_loss: 0.2826 - val_acc: 0.8909\n",
      "Epoch 2/20\n",
      "10255/10255 [==============================] - 24s - loss: 0.1456 - acc: 0.9460 - val_loss: 0.3246 - val_acc: 0.8773\n",
      "Epoch 3/20\n",
      "10255/10255 [==============================] - 24s - loss: 0.0762 - acc: 0.9745 - val_loss: 0.3791 - val_acc: 0.8679\n",
      "Epoch 4/20\n",
      "10255/10255 [==============================] - 24s - loss: 0.0498 - acc: 0.9835 - val_loss: 0.4353 - val_acc: 0.8654\n",
      "Epoch 5/20\n",
      "10255/10255 [==============================] - 24s - loss: 0.0363 - acc: 0.9872 - val_loss: 0.5035 - val_acc: 0.8580\n",
      "Epoch 6/20\n",
      "10255/10255 [==============================] - 24s - loss: 0.0205 - acc: 0.9941 - val_loss: 0.5773 - val_acc: 0.8608\n",
      "Epoch 7/20\n",
      "10255/10255 [==============================] - 24s - loss: 0.0182 - acc: 0.9944 - val_loss: 0.6150 - val_acc: 0.8549\n",
      "Epoch 8/20\n",
      "10255/10255 [==============================] - 25s - loss: 0.0164 - acc: 0.9948 - val_loss: 0.7361 - val_acc: 0.8450\n",
      "Epoch 9/20\n",
      "10255/10255 [==============================] - 26s - loss: 0.0176 - acc: 0.9952 - val_loss: 0.6625 - val_acc: 0.8511\n",
      "Epoch 10/20\n",
      "10255/10255 [==============================] - 30s - loss: 0.0124 - acc: 0.9957 - val_loss: 0.7830 - val_acc: 0.8499\n",
      "Epoch 11/20\n",
      "10255/10255 [==============================] - 26s - loss: 0.0081 - acc: 0.9972 - val_loss: 0.8253 - val_acc: 0.8523\n",
      "Epoch 12/20\n",
      "10255/10255 [==============================] - 28s - loss: 0.0152 - acc: 0.9942 - val_loss: 0.7159 - val_acc: 0.8515\n",
      "Epoch 13/20\n",
      "10255/10255 [==============================] - 27s - loss: 0.0095 - acc: 0.9972 - val_loss: 0.8318 - val_acc: 0.8474\n",
      "Epoch 14/20\n",
      "10255/10255 [==============================] - 28s - loss: 0.0088 - acc: 0.9966 - val_loss: 0.7712 - val_acc: 0.8369\n",
      "Epoch 15/20\n",
      "10255/10255 [==============================] - 27s - loss: 0.0059 - acc: 0.9980 - val_loss: 0.9051 - val_acc: 0.8489\n",
      "Epoch 16/20\n",
      "10255/10255 [==============================] - 32s - loss: 0.0070 - acc: 0.9976 - val_loss: 0.9500 - val_acc: 0.8412\n",
      "Epoch 17/20\n",
      "10255/10255 [==============================] - 30s - loss: 0.0091 - acc: 0.9968 - val_loss: 0.8069 - val_acc: 0.8525\n",
      "Epoch 18/20\n",
      "10255/10255 [==============================] - 28s - loss: 0.0060 - acc: 0.9981 - val_loss: 0.9007 - val_acc: 0.8440\n",
      "Epoch 19/20\n",
      "10255/10255 [==============================] - 27s - loss: 0.0057 - acc: 0.9977 - val_loss: 0.8853 - val_acc: 0.8390\n",
      "Epoch 20/20\n",
      "10255/10255 [==============================] - 26s - loss: 0.0039 - acc: 0.9987 - val_loss: 0.9389 - val_acc: 0.8505\n",
      "4960/5051 [============================>.] - ETA: 0s('Test score:', 0.93893316028803042)\n",
      "('Test accuracy:', 0.85052464853723653)\n"
     ]
    }
   ],
   "source": [
    "print('Train...')\n",
    "model.fit(tweet_train, label_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=20,\n",
    "          validation_data=(tweet_test, label_test))\n",
    "score, acc = model.evaluate(tweet_test, label_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
