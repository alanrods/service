{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESSING\n",
    "##### We read two different data set's (files) about ironic and non ironic tweets which has been already downloading by Twitter API. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ironics\n",
    "We already have a pre-build data set which contains:   \n",
    "\n",
    "* tweet id\n",
    "* four boolean flags  \n",
    "* tweet text  \n",
    "\n",
    "We just focus on the **tweet text** attribute,because we pretent to normalize it, I mean, we need to remove  \n",
    "some words and characters that we can see several times in any tweet, and it is possible that they affect the analysis, such as:  \n",
    "\n",
    "* #anything (hastag)\n",
    "* http://blahblah (link)\n",
    "* @anyone (mention)\n",
    "\n",
    "and, in this particular case, for the test porpuses:  \n",
    "\n",
    "* #sarcasmo\n",
    "* #ironÃ­a  \n",
    "\n",
    "and its variants (uppercase and lowercase).  \n",
    "*In a few couple of words*, we need to translate this:  \n",
    "\n",
    "### 111111111111111111:True:True:False:False:blah #Blah and @blah ðŸ˜’ #ironia #MX http://t.co/1234 \n",
    "\n",
    "into this:\n",
    "\n",
    "### 111111111111111111|ironic|blah Blah and blah ðŸ˜’ MX http://link\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with io.open('data/full_ironicos.txt','r',encoding='utf8') as f:\n",
    "    ironics = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_file = open('data/ironicos_normalizados.txt','w') \n",
    "\n",
    "for message in ironics:\n",
    "    ironic = [x.rstrip() for x in message.split(':',5)]\n",
    "    ironic = ironic[0::5]\n",
    "    tweet = ironic[1]\n",
    "    tweet = re.sub(r'(#(S|s)arcasmo|#(I|i)ron(i|\\W)a)','',tweet)\n",
    "    tweet = re.sub(r'#SARCASMO|#IRON(I|\\W)A','',tweet)\n",
    "    tweet = re.sub(r'https?://t.co/.\\w*','http://link', tweet)\n",
    "    tweet = re.sub(r'@.\\w*','@',tweet)\n",
    "    tweet = re.sub(r'#','',tweet)\n",
    "    #tweet = re.sub(r'|','-',tweet)\n",
    "    ironic[1] = tweet\n",
    "    ironic.insert(1,'ironic')\n",
    "    new_file.write('|'.join(ironic).encode('utf8')+'\\n')\n",
    "    \n",
    "new_file.close()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non ironics\n",
    "#### Building a normalized data set for non ironics tweets.  \n",
    "In this case we already have normalized tweet text and the tweet id, for this we just add the classificator attribute in order to build a similar dataset like *ironicos_normalizados.txt*.  \n",
    "It is important to consider, we build this data set with **68877** examples, in order to create three different corpus distributions:  \n",
    "Ironics vs Non ironics\n",
    "* 7653 vs 68877 (10-90%)\n",
    "* 7653 vs 17857 (30-70%)\n",
    "* 7653 vs 7653 (50-50%)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with io.open('data/full_background.txt','r',encoding='utf8') as f:\n",
    "    not_ironics = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_file = open('data/no_ironicos_normalizados.txt','w') \n",
    "for message in not_ironics[:68877]:\n",
    "    not_ironic = [x.rstrip() for x in message.split(':',1)]\n",
    "    tweet = not_ironic[1]\n",
    "    #not_ironic[1] = re.sub(r'|','-',tweet)\n",
    "    not_ironic.insert(1,'not_ironic')\n",
    "    new_file.write('|'.join(not_ironic).encode('utf8')+'\\n')\n",
    "\n",
    "new_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
